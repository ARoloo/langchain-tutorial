# üìö Einstieg in Langchain: Dein Wegweiser f√ºr KI-gest√ºtzte Projekte

## üéâ Willkommen zu unserem Langchain-Tutorial!
In dieser Anleitung werden Sie die Grundlagen der Integration von KI-Technologien kennenlernen. Sie werden entdecken, wie Sie KI-Agenten effizient auf Ihrem eigenen Computer nutzen k√∂nnen, um Ihre Projekte zu bereichern. Diese App demonstriert die nahtlose Verwendung von leistungsstarken Sprachmodellen unter Wahrung Ihrer Datensicherheit und Privatsph√§re. Lassen Sie uns gemeinsam die aufregende Welt der KI erkunden und lernen, wie Sie Ihre eigenen intelligenten Anwendungen entwickeln k√∂nnen!

## üìÇ Inhaltsverzeichnis
- [Technologien](#technologien)
- [Voraussetzungen](#voraussetzungen)
- [Installation](#installation)
- [Ausf√ºhren von Python-Programmen im Container](#ausf√ºhren-von-python-programmen-im-container)

## üõ†Ô∏è Technologien
- **Langchain**: Ein Framework zur Entwicklung von Anwendungen, die von Sprachmodellen betrieben werden. Mehr dazu unter [Langchain](https://www.langchain.com/).
- **Mistral**: Ein Werkzeug zum Ausf√ºhren gro√üer Sprachmodelle lokal. Besuchen Sie [Mistral](https://mistral.com) f√ºr weitere Informationen.
- **Docker**: Eine Plattform zur Automatisierung der Bereitstellung von Anwendungen in Containern. Erfahren Sie mehr √ºber [Docker](https://www.docker.com/).

## üåê LLM-Modelle
In dieser Sektion werden verschiedene LLM-Modelle vorgestellt, die Sie verwenden k√∂nnen, darunter **ChatGPT** und **Ollama**. Diese Beispiele werden unter Verwendung der **Mistral API** erstellt. Sie k√∂nnen die leistungsstarken Sprachmodelle nutzen, um Ihre Projekte zu bereichern und innovative L√∂sungen zu entwickeln.

### Verf√ºgbare Modelle:
- **ChatGPT**: Ein fortschrittliches KI-Modell, das nat√ºrliche Sprache versteht und erzeugt.
- **Ollama**: Ein weiteres KI-Modell, das sich durch seine Flexibilit√§t und Anpassungsf√§higkeit auszeichnet.

## Voraussetzungen
- [Docker Installationsanleitung](https://docs.docker.com/get-docker/)
- [Docker Compose Installationsanleitung](https://docs.docker.com/compose/install/)

## üöÄ Installation
Um diese Anwendung auszuf√ºhren, stellen Sie sicher, dass Sie Docker und Docker Compose installiert haben. Befolgen Sie die folgenden Schritte, um die Anwendung einzurichten:

### Schritt 1: Klonen des Git-Repositorys
Um das Repository zu klonen, verwenden Sie den folgenden Befehl in Ihrem Terminal:
```bash
 git clone <repository_url>
```
Dieser Befehl erstellt eine lokale Kopie des Repositorys auf Ihrem Computer. Stellen Sie sicher, dass Sie `<repository_url>` durch die tats√§chliche URL des Repositorys ersetzen.

### Schritt 2: Navigieren Sie zum Projektverzeichnis
Nachdem Sie das Repository geklont haben, navigieren Sie in das Projektverzeichnis mit dem Befehl:
```bash
 cd <repository_directory>
```
Ersetzen Sie `<repository_directory>` durch den Namen des Ordners, der erstellt wurde, als Sie das Repository geklont haben. Dieser Ordner enth√§lt alle notwendigen Dateien zum Ausf√ºhren der Anwendung.

### Schritt 3: Bauen und Ausf√ºhren der Anwendung
Sobald Sie im Projektverzeichnis sind, f√ºhren Sie den folgenden Befehl aus, um die Anwendung zu bauen und zu starten:
```bash
 docker-compose up -d --build
```
Dieser Befehl startet die Anwendung im Hintergrund und baut die notwendigen Docker-Container.

### Zugriff auf den Container
Um auf den Container zuzugreifen, verwenden Sie den folgenden Befehl:
```bash
docker exec -ti <container_name> bash
```
Ersetzen Sie `<container_name>` durch den tats√§chlichen Namen Ihres Containers.

## Ausf√ºhren von Python-Programmen im Container
Sobald Sie Zugriff auf den Container haben, k√∂nnen Sie Python-Programme ausf√ºhren. Verwenden Sie den folgenden Befehl, um ein bestimmtes Python-Skript zu starten:
```bash
python filename.py
```
Ersetzen Sie 'filename.py' durch den Namen des Python-Skripts, das Sie ausf√ºhren m√∂chten. Stellen Sie sicher, dass das Skript im aktuellen Verzeichnis vorhanden ist oder geben Sie den vollst√§ndigen Pfad an, um es erfolgreich zu starten.
